---
title: "Working with qData"
author: "James Hollway"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Working with qData}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
NOT_CRAN <- identical(tolower(Sys.getenv("NOT_CRAN")), "true")
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  purl = NOT_CRAN,
  eval = NOT_CRAN
)
```

## Discovering data

The first thing users of the package will want to do is to identify
datasets that might contribute to their research goals. 
Since some of these data packages are too big for CRAN 
(the main though not only R package repository), 
we expect that their developers will instead choose
to make their packages available on Github. 
Github is huge though, either way it can be difficult to identify salient data. 
We have tried to make this easy by allowing the reporting of all datasets 
in the ecosystem that we know of that currently pass our tests.

```{r, eval=NOT_CRAN}
library(qData)
get_packages()
```

In the future, this function will report more details about the datasets
included in each package and their provenance.

## Understanding data

Packages in the `{qData}` ecosystem have the advantage to facilitate comparison 
and analysis of multiple datasets in a specific domain of global governance. 
This is possible with a particular coding system which follows the same 
principles across the different packages. 

In `{qStates}` for example, all datasets from the states database contain 
variables named `Beg`and `End` which represent the beginning and ending date 
of an episode of state sovereignty.

In `{qEnviron}`, the agreements database also have the `Beg` and `End` variables 
but those are attributed to treaties (signature and term dates). 
For the memberships database, `Beg` and `End` represent when a relationship 
between states and an agreement starts (either signature, ratification or entry into force) 
and ends (either withdrawal or term).

This specific variable name allows the comparison across the datasets which 
have different sources but same informations. 
It enables to point out the recurrence, 
difference or absence of observations between the datasets and extract
more robust data when researching on a particular governance domain. 

## Loading data

For now, let us say that we wish to download the `{qStates}` package,
which offers a set of datasets related to state actors in global governance. 
We can download and install the latest release version of
the `{qStates}` package using the same function as before, only
specifying which package we want to 'get':

```{r, eval=FALSE}
get_packages("globalgov/qStates")
```

Once the qpackage has been downloaded and installed, we are free to work
with the data it contains. 
This `{qStates}` package includes several datasets.
We can get a quick summary of the datasets included in this
package with the following command:

```{r}
data(package = "qStates")
```

Let's take a quick look at the main `states` data in this package.

```{r}
data(states, package = "qStates")
states
```

We can see that there are three named datasets relating to states here:
`COW` (Correlates of War), `GW` (Gleditsch and Ward), and `ISD`
(International Systems Dataset). Each of these datasets has their
advantages and so we may wish to understand their differences, summarise
variables across them, and perhaps also rerun models across them.

To retrieve an individual dataset from this database,
we can use the `pluck()` function from the `{purrr}` package.

```{r}
COW <- purrr::pluck(states, "COW")
```

However, the real value of qData packages is that multiple datasets
relating to the same phenomenon are presented together.
This facilitates comparison, the subject of the next section.

## Comparing data

First of all, we want to understand what the differences are between these datasets.
One important way to understand the relationship between these datasets is 
to understand what their relative advantages and disadvantages are.
For example, one dataset may be long (has many observations) 
while another is shorter but wider (has more variables).
One might include details further back in history while the other is more recent,
but include more missing data or less precise data (i.e. coded at a less granular level)
than another with a more restrictive 
Or one might appear complete yet offer less information on where the original data points
were sourced or how certain variables were coded,
while another provides an extensive and transparent codebook that facilitates replication.
Below we show how one might compare the data in `states` in these ways.

### Differences in documentation

We can bring up the database level documentation using the following command:
`?states`.
This documentation informs the user on the various datasets that are present in
the database as well as the most important metadata of the various datasets. 
If we want a more detailed summary of the various levels of data 
and sources we can run `data_source()` and `data_contrast()` functions as
outlined below.

### Using `data_source()` and `data_contrast()`

The `data_source()` function displays bibliographic references for the datasets
in a qPackage or within a database.

```{r}
data_source(pkg = "qStates", database = NULL, dataset = NULL)
```

The `data_contrast()` function returns a data frame with the key metadata 
of each level of data objects (qPackage, database, and dataset).
This metadata includes the following elements:

* Number of unique observations
* Number of rows
* Number of columns
* Earliest beginning date
* Latest end date
* Source URL

```{r}
data_contrast(pkg = "qStates", database = NULL, dataset = NULL)
```

If we were specifically interested in the `COW` dataset of the `states`
database, we would specify the output by setting the database and the dataset
arguments to the corresponding value. 

```{r}
data_contrast(pkg = "qStates", database = "states",
              dataset = "COW")
```

## Preparing data

Now that we have visualized the data that rests in the `states` database, let us
examine how to select and collapse it. To that end, we will consider two 
essential tools of the `{qData}` package that will facilitate data manipulation
prior to your analysis.

### Resolve data

First up is the `resolve()` family of functions. This family of functions will
help you resolve uncertainties in your data objects. For example, the main
use-case in qStates will be uncertainties in dates when the original dataset 
contains a beginning date range instead of an exact beginning date which will
often happen when considering historical states.

The `resolve()` family of functions contains the following functions.

- `resolve_min()`: returns the minimum of the range
- `resolve_max()`: returns the maximum of the range
- `resolve_mean()`: returns the mean of the range
- `resolve_mode()`: returns the mode of the range
- `resolve_median()`: returns the median of the range

Let us now consider the following example:

```{r}
data <- dplyr::tibble(ID = c("CHE", "FRA", "GER"),
                      Name = c("Switzerland", "France", "Germany"),
                      Date = c("1291-08-01", "1815-01-01:1815-12-31", NA))
data
# We now apply resolve_mean to the date vector to make an informed choice about
# the uncertainty in the original dataset.
data$Date <- resolve_mean(data$Date)
data
```

### Collapse data

After having used the `resolve()` family of functions to resolve uncertainties
in the data, we will take a look at the possibilities to join the different
dataframes into one for further analysis. `{qData}` provides the ideal
solution for this task in the form of the `collapse()` family of functions.

The `collapse()` family of functions contains the following functions.

- `collapse_select()` returns the specified column
- `collapse_full()` returns the entire set of observations
- `collapse_inner()` returns the overlapping set of observations
- `collapse_left()` returns the set of overlapping observations plus all
observations in the left dataset
- `collapse_right()` returns the set of overlapping observations plus all
observations in the right dataset

These functions follow the same syntax as standard SQL join commands. To get a
quick visual refresher on these methods read
[this article](https://rpubs.com/jcross/joins). Let us now consider the
following examples to illustrate the functions.

```{r}
# Select a dataset in a database
selected <- collapse_select(states, "COW")
selected
# Full join an entire database
COWISDfull <- collapse_full(list(states$COW, states$ISD), "ID")
COWISDfull
# Inner join an entire database
COWISDinner <- collapse_inner(list(states$COW, states$ISD), "ID")
COWISDinner
# Left join an entire database
COWISDleft <- collapse_left(list(states$COW, states$ISD), "ID")
COWISDleft
```

### A practical example of inference sensitivity to data sources:

Next we may be interested in whether any relationships we are interested in or inferences we want to draw
are sensitive to which data we use.
That is, we are interested in the robustness of any results to different data specifications.
None of the `states` datasets are particularly wide, but let us try and examine the "Beg" variable to start with.

We can start by exploring whether our conclusion about when states first gained sovereignty
would differ depending on which dataset we use.
We can use the `purrr::map()` function used above, but this time pass it the `mean()` function
and tell it to operate on just the "Beg" variable (removing any NAs).
Since qData datasets are always ordered by "Beg" (and then "ID"),
we can remove any subsequent (duplicated) entries by ID to concentrate on first appearances.

```{r}
states %>% 
  purrr::map(function(x){
    x %>% dplyr::filter(!duplicated(ID)) %>%
      dplyr::summarise(mean(Beg, na.rm = TRUE))
  })
```

It seems that there is some variation there.
Of course, these averages are biased in the sense that these datasets are left-censored.
Any state gaining sovereignty prior to 1816 is simply assigned as "1816-01-01".
