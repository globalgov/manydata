---
title: "Working with manydata"
author: "James Hollway, Henrique Sposito, and Jael Tan"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Working with manydata}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r lib}
library(manydata)
```

## Discovering data

The first thing users of the package will want to do is to identify
datasets that might contribute to their research goals. 
We expect that their developers will choose
to make their packages available on GitHub.
To make it easier to identify many packages,
we have developed the `call_packages()` function.
The function lists the many packages available and allow users to download them.

Let us say that we wish to download the `{manystates}` package,
which offers a set of datasets related to state actors in global governance. 
We can download and install the latest release version of
the `{manystates}` package by specifying the package name: `call_packages("manystates")`.

```{r discover, eval=FALSE}
call_packages() # returns list of many packages
```

The `call_sources()` function can be used to view the sources, URLs,
and variable changes for the datasets within a database within a many package.

```{r source}
call_sources(package = "manydata", database = "emperors")
```

## Understanding data

Packages in the many packages universe have the advantage to facilitate comparison 
and analysis of multiple datasets in a specific domain of global governance. 
This is possible with a particular coding system which follows the same 
principles across the different packages.

For instance, in the data packages on international agreements
(including `{manyenviron}`, `{manytrade}`, and `{manyhealth}`),
the `agreements` and `memberships` databases have standardised date variables
`Begin` and `End` that contain the beginning,
signature, entry into force, and end dates of treaties respectively.
The beginning date is derived from the signature or entry into force date,
whichever is the earliest available date for the treaty.
These specific variable name allows the comparison of information across 
datasets that have different sources.
It enables users to point out the recurrence, 
difference or absence of observations between the datasets and
extract more robust data when researching on a particular governance domain. 

The memberships database contains additional date variables on each state member's ratification,
signature, entry into force, and end dates for each treaty.
Data in the memberships database is comparable across datasets through standardised state names and stateIDs,
made possible with the `manypkgs::code_states()` function.
More information on each state, including its `Begin` and `End` date,
can be found in the `{manystates}` package.

## Loading data

For now, let's work with the Roman Emperors database included in manydata. 
We can get a quick summary of the datasets included in this
package with the following command:

```{r load}
data(package = "manydata")
data(emperors, package = "manydata")
emperors
```

We can see that there are three named datasets relating to emperors here:
`wikipedia` (dataset assembled from Wikipedia pages), `UNVR` (United Nations of Roman Vitrix),
and `britannica` (Britannica Encyclopedia List of Roman Emperors).
Each of these datasets has their advantages and so we may wish
to understand their differences,
summarise variables across them, and perhaps also rerun models across them.

To retrieve an individual dataset from this database,
we can use the `pluck()` function.

```{r pluck}
wikipedia <- pluck(emperors, "wikipedia")
```

However, the real value of the various 'many packages' is that multiple datasets
relating to the same phenomenon are presented together.

## Comparing data

First of all, we want to understand the differences between the datasets in a database.
One important way to understand the relationship between these datasets is 
to understand what their relative advantages and disadvantages are.
For example, one dataset may be long (has many observations) 
while another is shorter but wider (has more variables).
One might include details further back in history while the other is more recent,
but contain more missing data or less precise data (i.e. coded at a less granular level)
than another with a more restrictive time range. 
Or one might appear complete yet offer less information on where the original
data points were sourced or how certain variables were coded,
while another provides an extensive and transparent codebook
that facilitates replication.

### Comparing and ploting

We can bring up the database level documentation using: `?emperors`.
This informs users on the datasets present in the database
as well as the variables in the various datasets. 
If we want a more detailed summary of the various levels of data 
and sources, we can use the `compare_` family of functions.

The `compare_data()` function returns a tibble with the key metadata 
of each dataset within the specified database of a many package.

```{r compare data}
compare_data(emperors)
```

The `compare_overlap()` function returns a tibble with the number of overlapping observations for a specified variable (specify using the `key` argument) across datasets within the database.
This can also be visualized with the `plot_overlap()` function.

```{r overlap}
compare_overlap(emperors, key = "ID")
plot(compare_overlap(emperors, key = "ID"))
```

The `compare_missing()` function returns a tibble with the number and percentage of missing observations in datasets within database.
This can also be visualized with the `plot_missing()` function.

```{r missing}
compare_missing(emperors)
plot(compare_missing(emperors))
```

Finally, both the `compare_categories()` and the `plot_categories()` functions help researchers identify how variables across datasets within a database relate to one another.
Observations are matched by an "ID" variable to facilitate comparison.
The categories here include 'confirmed', 'majority', 'unique', 'missing', and 'conflict'.
Observations are 'confirmed' if all non-NA values are the same across all datasets,
and 'majority' if the non-NA values are the same across most datasets.
'Unique' observations are present in only one dataset and
'missing' observations indicate there are no non-NA values across all datasets for that variable.
Observations are in 'conflict' if datasets have different non-NA values.


```{r categories}
compare_categories(emperors, key = "ID")
plot(compare_categories(emperors, key = "ID"))
```

### An example of inference sensitivity to data sources

Next we may be interested in whether any relationships we are interested in
or inferences we want to draw are sensitive to which data we use.
That is, we are interested in the robustness of any results to different data specifications.

We can start by exploring whether our conclusion about when emperors began their reign
would differ depending on which dataset we use.
We can use the `purrr::map()` function used above, but this time pass it the `mean()` function
and tell it to operate on just the "Beg" variable, which represents 
when emperors began their reign (removing any NAs).
Since manydata datasets are always ordered by "Begin" (and then "ID"),
we can remove any subsequent (duplicated) entries by ID to concentrate on first appearances.

```{r compare, message=FALSE, warning=FALSE}
library(dplyr)
emperors %>% 
  purrr::map(function(x){
    x %>% dplyr::filter(!duplicated(ID)) %>%
      dplyr::summarise(mean(Beg, na.rm = TRUE))
  })
```

## Consolidating data

Now that we have compared the data and looked at some of the different inferences drawn,
let us examine how to select and consolidate databases.

The `consolidate()` function facilitates consolidating a set of datasets, or a database,
from a 'many' package into a single dataset with some combination of the rows and columns.
The function includes separate arguments for rows and columns,
as well as for how to resolve conflicts in observations across datasets.
The key argument indicates the column to collapse datasets by.
This provides users with considerable flexibility in how they combine data.

For example, users may wish to see units and variables coded in "any" dataset
(i.e. units or variables present in at least one of the datasets in the 
database) or units and variables coded in "every" dataset (i.e. units or
variables present in all of the datasets in the database).

```{r consolidate}
consolidate(database = emperors, rows = "any", cols = "any",
            resolve = "coalesce", key = "ID")
consolidate(database = emperors, rows = "every", cols = "every",
            resolve = "coalesce", key = "ID")
```

Users can also choose how they want to resolve conflicts between observations in
`consolidate()` with several 'resolve' methods:

* coalesce: the first non-NA value 
* max: the largest value
* min: the smallest value
* mean: the average value
* median: the median value
* random: a random value

```{r resolve}
consolidate(database = emperors, rows = "any", cols = "every", resolve = "max", key = "ID")
consolidate(database = emperors, rows = "every", cols = "any", resolve = "min", key = "ID")
consolidate(database = emperors, rows = "every", cols = "every", resolve = "mean", key = "ID")
consolidate(database = emperors, rows = "any", cols = "any", resolve = "median", key = "ID")
consolidate(database = emperors, rows = "every", cols = "every", resolve = "random", key = "ID")
```

Users can even specify how conflicts for different variables should be 'resolved':

```{r different}
consolidate(database = emperors, rows = "any", cols = "every", resolve = c(Beg = "min", End = "max"), key = "ID")
```

Alternatively, users can "favour" a dataset in a database over others:

```{r favour}
consolidate(database = favour(emperors, "UNRV"), rows = "every", cols = "any", resolve = "coalesce", key = "ID")
```

Users can, even, declare multiple key ID columns to consolidate a database or multiple datasets:

```{r multiple}
consolidate(database = emperors, rows = "any", cols = "any", resolve = c(Death = "max", Cause = "coalesce"),
            key = c("ID", "Beg"))
```
